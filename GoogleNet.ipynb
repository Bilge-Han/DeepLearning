{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMTqkksXVIAMFdzhev4BPN4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"513SnitqAeHe"},"outputs":[],"source":["# GoogleNet\n","# 2014'te sınıflandırma'da 1.olmuştur\n","# Goggle araştırmacıları tarafından geliştirilmiş bir model.\n","# GoogleLeNet derler LeNet altyapısı kullanmış\n","# AlexNet'ten daha az parametreye sahip, daha başarılı model.\n","# 22 katmandan oluşuyor.\n","# Inceptıon modullleri : getirdiği yenilik, diğerlerinde peş peşe conv vs uyguluyorduk, burada aynı anda yan yana uyguluyoruz.\n","# yani farklı filtreleri aynı görüntüye uygulayıp tek bir çıktıda birleştiriyoruz.\n","# tam bağımlı katmanlar yok.\n","# 5 milyon params\n","# paralel filtrelerden çıkan feature maplerin birleştirilmesi için boyutlarının aynı olması lazım!.\n","# örn 3x3 filtre ve 5x5 filtrede , 5x5 olana paddingi fazla ekleyip daha da küçültürüz.\n","# 1x1 conv ne işe yarar : bir tane sayı demektir, bir sayıyı bütün görüntüyle çarparak yeni görüntü elde ederiz:\n","# bottleneck denen darboğazvar, filtre sayısını azaltmak istiyoruz. x*x yerine, 1x1 kullanarak daha az işlemle yapar. 1x1ler genelde veriyi küçültmek için kullanılır.\n","# temel problem ne? Karmaşıklık çok fazla \n","# filtre birleştirirken toplam çıktı ne olucak? boyutlar aynı olduğu için, filtre adetlerini toplarız.\n","# hesaplama maliyeti yüksek (854m operations(işlem))\n","# her bir katmanda filtre arttığı için problemdir:\n","# bunun için bottleneck (1x1 conv) ekleniyor, feature derinliğini düşürmek için. (bknz: maliyet düştü : 353m operations (işlem))\n","# önce bottlencek ile daraltma sonra işlemlerde derinleştiririz.\n","# peki geçiçi çıktıların amacı nedir : çok derin olduğu için ara katmanlarda çıktı alıyoruz ve son katmandaki çıktı ile karşılaştırabiliyoruz.\n","\n","# GoogleNet ne getirdi:\n","# Cnn modellerinin yalnızca peş peşe gelen conv katmanlardan oluşamayacağını, ınceptıon gibi birden fazla paralel yapıların kurulabileceğini\n","# bu yapıların performansı ve hesaplama derinliğini arttırabileceğini göstermiştir.\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","\n","from keras.utils import np_utils\n","from keras.models import Sequential, Model\n","from keras.layers.core import Flatten,Dense,Dropout\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D ,Input,AveragePooling2D,GlobalAveragePooling2D\n","from tensorflow.keras.layers import Concatenate\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam,SGD"],"metadata":{"id":"rtZ7FomYFUST"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bunun için veri alıp okuyoruz.\n","\n","train_path='./drive/MyDrive/Deep Learning/chest_xray/train'\n","test_path='./drive/MyDrive/Deep Learning/chest_xray/test'\n","\n","trainGen=ImageDataGenerator(\n","    rescale=1./255,\n","    validation_split=0.1      # validation verisi ayırdı.\n",")\n","\n","valGen=ImageDataGenerator(rescale=1./255)\n","testGen=ImageDataGenerator(rescale=1./255)\n","\n","# Veri okuma yöntemleri\n","# flow : görüntüleri okursunuz, listeye atarsanız, liste içerisinden flow(okuyabilirsiniz) atabilirsiniz \n","# flow_from_directory : bir directory'den oku listeye atma, ihtiyacım olduğunda getir\n","\n","trainData=trainGen.flow_from_directory(\n","    train_path,               # bu directory'den oku\n","    target_size=(224,224),    # hedef ne olsun, tüm görüntüler 28'e 28 olsun dedik, ne kadar büyük okursak o kadar kaliteli görüntü çıkar.\n","    class_mode= 'binary',     # okuma türünü belirliyoruz  -categorical dersek= 2D one-hut encoding yapılmış şekilde okur, -binary dersek= binary şekilde bir bir okur\n","    batch_size=32,\n","    color_mode='rgb',\n","    subset='training'         \n","    )\n","\n","valData=trainGen.flow_from_directory(\n","    test_path,           \n","    target_size=(224,224),    \n","    class_mode= 'binary',           \n","    batch_size=32,\n","    color_mode='rgb',\n","    subset='validation'      # ayırdığımız validation datayı kullandık.\n","    )\n","\n","testData=trainGen.flow_from_directory(\n","    test_path,           \n","    target_size=(224,224),    \n","    class_mode= 'binary',           \n","    batch_size=32,\n","    color_mode='rgb',\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UE193AAQFes5","executionInfo":{"status":"ok","timestamp":1686483202235,"user_tz":-180,"elapsed":336,"user":{"displayName":"Bilge Acar","userId":"06611286343710406371"}},"outputId":"5e819a26-0f84-4699-d029-efa1a4714cb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4695 images belonging to 2 classes.\n","Found 62 images belonging to 2 classes.\n","Found 624 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["def inception(x, filtreler):\n","  #1x1\n","  yol1=Conv2D(filters=filtreler[0],kernel_size=1,strides=1,padding='same',activation='relu')(x)\n","\n","  #1x1 -> 3x3\n","  yol2=Conv2D(filters=filtreler[1][0],kernel_size=1,strides=1,padding='same',activation='relu')(x)\n","  yol2=Conv2D(filters=filtreler[1][1],kernel_size=1,strides=1,padding='same',activation='relu')(yol2)\n","\n","  #1x1 -> 5x5\n","  yol3=Conv2D(filters=filtreler[2][0],kernel_size=1,strides=1,padding='same',activation='relu')(x)\n","  yol3=Conv2D(filters=filtreler[2][1],kernel_size=1,strides=1,padding='same',activation='relu')(yol3)\n","\n","  #3x3 max -> 1x1\n","  yol4=MaxPooling2D(pool_size=(3,3),strides=1,padding='same')(x)\n","  yol4=Conv2D(filters=filtreler[3],kernel_size=1,strides=1,padding='same',activation='relu')(yol4)\n","\n","  return Concatenate(axis=-1)([yol1,yol2,yol3,yol4])"],"metadata":{"id":"H1pLyS3jGAAr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Çıkış katmanı\n","def auxilary(x,name=None):\n","  layer=AveragePooling2D(pool_size=(5,5),strides=3,padding='valid')(x)\n","  layer=Conv2D(128,kernel_size=1,padding='same',activation='relu')(layer)\n","  layer=Flatten()(layer)\n","  layer=Dense(256,activation='relu')(layer)\n","  layer=Dense(1,activation='sigmoid',name=name)(layer) # buraya 1 yazdıkta diğer prob. 1000 oluyor.\n","\n","  return layer"],"metadata":{"id":"14p53WTSHawi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#bir input tanımladık.\n","input=Input(shape=(224,224,3))\n","\n","#stage 1\n","x=Conv2D(64,kernel_size=(7,7),strides=(2,2),padding='same',activation='relu')(input)\n","x=MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)                     #alexnetin sunduğu overlapping\n","x=Conv2D(192,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x)\n","x=MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')\n","\n","#stage 2\n","x=inception(x,[64,(96,128),(16,32),32]) #3a\n","x=inception(x,[128,(128,192),(32,96),64]) #3b\n","x=MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","\n","#stage 3\n","x=inception=(x,[192,(96,208),(16,48),64]) #4a\n","aux1=auxilary(x,name='aux1')\n","x=inception(x,[160,(112,224),(24,64),64]) #4b\n","x=inception(x,[128,(128,256),(24,64),64]) #4c\n","x=inception(x,[112,(144,288),(32,64),64]) #4d\n","aux2=auxilary(x,name='aux2')\n","x=inception(x,[256,(160,320),(32,128),128]) #4e\n","x=MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","\n","#stage 4\n","x=inception(x,[256,(160,320),(32,128),128]) #5a\n","x=inception(x,[384,(192,384),(48,128),128]) #5b\n","x=AveragePooling2D(pool_size=(7,7),strides=1,padding='valid')(x)\n","x=Flatten()(x)\n","out=Dense(1,activation='sigmoid',name='cikis')(x)\n","\n","model=Model(inputs=input,outputs=[out,aux1,aux2])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"Yt9Y2KFEH-3q","executionInfo":{"status":"error","timestamp":1686483212614,"user_tz":-180,"elapsed":5,"user":{"displayName":"Bilge Acar","userId":"06611286343710406371"}},"outputId":"f3cb2d98-e168-4852-e86b-53e696855e60"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-65cdcfe62dda>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#stage 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#3a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#3b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-44a573094a4e>\u001b[0m in \u001b[0;36minception\u001b[0;34m(x, filtreler)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltreler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#1x1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0myol1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiltreler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#1x1 -> 3x3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# which does not have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;34mf\"Inputs to a layer should be tensors. Got '{x}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34mf\"(of type {type(x)}) as input for layer '{layer_name}'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got '<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f1ade86bfd0>' (of type <class 'keras.layers.pooling.max_pooling2d.MaxPooling2D'>) as input for layer 'conv2d_30'."]}]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy',optimize='sgd',metrics=['accuracy'])\n","history=model.fit(trainData,validation_data=valData,epochs=10,batch_size=32)"],"metadata":{"id":"gtJQ8lMbJLLS"},"execution_count":null,"outputs":[]}]}